{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_ALL_Master",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meO7ZaISZfZ1",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhdjgZWAZ60C",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQH4OCHZ9bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_",
        "colab_type": "text"
      },
      "source": [
        "# BERT All model master"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdMmwCJFaT8F",
        "colab_type": "text"
      },
      "source": [
        "### Set up your TPU environment\n",
        "\n",
        "In this section, you perform the following tasks:\n",
        "\n",
        "*   Set up a Colab TPU running environment\n",
        "*   Verify that you are connected to a TPU device\n",
        "*   Upload your credentials to TPU to access your GCS bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBP35oCDmbF",
        "colab_type": "text"
      },
      "source": [
        "### Prepare and import BERT modules\n",
        "â€‹\n",
        "With your environment configured, you can now prepare and import the BERT modules. The following step clones the source code from GitHub and import the modules from the source. Alternatively, you can install BERT using pip (!pip install bert-tensorflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "import tokenization\n",
        "\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRu1aKO1D7-Z",
        "colab_type": "text"
      },
      "source": [
        "### Prepare for training\n",
        "\n",
        "This next section of code performs the following tasks:\n",
        "\n",
        "*  Specify task and download training data.\n",
        "*  Specify BERT pretrained model\n",
        "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model : PAWS_QQP_Model ; Data : Final_Data/paws_qqp/\n",
        "# Model : PAWS_Wiki_Model ; Data : Final_Data/paws_wiki/\n",
        "BERT_MODEL = 'cased_L-24_H-1024_A-16' #@param {type:\"string\"}\n",
        "TEST = 'NO_FINE_TUNNING' #@param {type:\"string\"}\n",
        "assert TEST in ('DENSE_CLASSIFICATION','NORMAL',\"CNN\",'NO_FINE_TUNNING'), 'Test not supported'\n",
        "BUCKET = 'w266-duplicate-questions-rl-gg' #@param {type:\"string\"}\n",
        "bucket_name=BUCKET\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "TASK = 'QQP' #@param {type:\"string\"}\n",
        "assert TASK in ('MRPC', 'CoLA','QQP','PAWS'), 'Only (MRPC, CoLA, QQP, PAWS) are demonstrated here.'\n",
        "SUB_TASK=\"QQP\" #@param {type:\"string\"}\n",
        "assert SUB_TASK in ('QQP','WIKI','ALL_FILE','STACK'), 'Only (QQP, PAWS) are demonstrated here.'\n",
        "# Download glue data.\n",
        "if TASK != \"PAWS\":\n",
        "  #QQP Original\n",
        "  !gsutil -m cp gs://{bucket_name}/Final_Data/QQP/dev.tsv /content/Final_Data/QQP/dev.tsv\n",
        "  !gsutil -m cp gs://{bucket_name}/Final_Data/QQP/train.tsv /content/Final_Data/QQP/train.tsv\n",
        "  TASK_DATA_DIR = \"Final_Data/QQP/\"\n",
        "  OUTPUT_DIR = \"gs://{}/thursday/{}/QQP_Model/\".format(BUCKET, TEST)\n",
        "  SUB_TASK=\"NA\"\n",
        "else:\n",
        "  if SUB_TASK==\"QQP\":\n",
        "    # PAWS_QQP\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/paws_qqp/dev.tsv /content/Final_Data/paws_qqp/dev.tsv\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/paws_qqp/train.tsv /content/Final_Data/paws_qqp/train.tsv \n",
        "    TASK_DATA_DIR = 'Final_Data/paws_qqp/'\n",
        "    OUTPUT_DIR = 'gs://{}/thursday/{}/PAWS_QQP_Model/'.format(BUCKET, TEST) \n",
        "    # PAWS_WIKI\n",
        "  if SUB_TASK==\"WIKI\":\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/paws_wiki/dev.tsv /content/Final_Data/paws_wiki/dev.tsv\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/paws_wiki/train.tsv /content/Final_Data/paws_wiki/train.tsv\n",
        "    TASK_DATA_DIR = 'Final_Data/paws_wiki/'\n",
        "    OUTPUT_DIR = 'gs://{}/thursday/{}/PAWS_WIKI_Model/'.format(BUCKET, TEST) \n",
        "  if SUB_TASK==\"ALL_FILE\":\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/all_data/dev.tsv /content/Final_Data/all_data/dev.tsv\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/all_data/train.tsv /content/Final_Data/all_data/train.tsv\n",
        "    TASK_DATA_DIR = 'Final_Data/paws_wiki/'\n",
        "    OUTPUT_DIR = 'gs://{}/thursday/{}/PAWS_WIKI_Model/'.format(BUCKET, TEST)\n",
        "  \n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "\n",
        "PREDICT=True #@param{type:\"boolean\"}\n",
        "STACK=True #@param{type:\"boolean\"}\n",
        "RUN_FROM_CHECKPOINT=False #@param{type:\"boolean\"}\n",
        "if STACK:\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/StackExchange/dev.tsv /content/Final_Data/StackExchange/dev.tsv\n",
        "    !gsutil -m cp gs://{bucket_name}/Final_Data/StackExchange/train.tsv /content/Final_Data/StackExchange/train.tsv\n",
        "    STACK_DATA_DIR = 'Final_Data/paws_wiki/'\n",
        "    \n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "#https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'\n",
        "\n",
        "#Replace run_classifier_with_tfhub.py with the correct \n",
        "if TEST!=\"NORMAL\":\n",
        "  !rm /content/bert_repo/run_classifier_with_tfhub.py\n",
        "  !git clone https://github.com/dataSci-rigo/xlnet-QQP-TPU.git\n",
        "  if TEST==\"NO_FINE_TUNNING\":\n",
        "    !cp xlnet-QQP-TPU/run_classifier_with_tfhub.py /content/bert_repo/run_classifier_with_tfhub.py\n",
        "  if TEST==\"CNN\":\n",
        "    !cp xlnet-QQP-TPU/CNN/run_classifier_with_tfhub.py /content/bert_repo/run_classifier_with_tfhub.py\n",
        "  if TEST==\"DENSE_CLASSIFICATION\":\n",
        "    !cp xlnet-QQP-TPU/class_layer/run_classifier_with_tfhub.py /content/bert_repo/run_classifier_with_tfhub.py\n",
        "!ls bert_repo/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcpfl4N2EdOk",
        "colab_type": "text"
      },
      "source": [
        "Now let's load tokenizer module from TF Hub and play with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvnktVYmvXJI",
        "colab_type": "text"
      },
      "source": [
        "## Data Processors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TylDOYd-6AH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n",
        "tokenizer.tokenize(\"This here's an example of using the bert tokenizer\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gbk0a7JHezt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QQPProcessor(run_classifier.DataProcessor):\n",
        "  \"\"\"Processor for the Quora Question pair data set.\"\"\"\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"train.tsv\")), 'train')\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    \"\"\"Reading dev.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"dev.tsv\")), 'dev')\n",
        "  \n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(os.path.join(data_dir,\"test.tsv\")), 'test')\n",
        "  \n",
        "  def get_predict_examples(self, sentence_pairs):\n",
        "    \"\"\"Given question pairs, conevrting to list of InputExample\"\"\"\n",
        "    examples = []\n",
        "    for (i, qpair) in enumerate(sentence_pairs):\n",
        "      guid = \"predict-%d\" % (i)\n",
        "      # converting questions to utf-8 and creating InputExamples\n",
        "      text_a = tokenization.convert_to_unicode(qpair[0])\n",
        "      text_b = tokenization.convert_to_unicode(qpair[1])\n",
        "      # We will add label  as 0, because None is not supported in converting to features\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=0))\n",
        "    return examples\n",
        "  def convert_examples(self, sentence_pairs):\n",
        "    \"\"\"Given question pairs, conevrting to list of InputExample\"\"\"\n",
        "    examples = []\n",
        "    for (i, qpair) in enumerate(sentence_pairs):\n",
        "      guid = \"predict-%d\" % (i)\n",
        "      # converting questions to utf-8 and creating InputExamples\n",
        "      text_a = tokenization.convert_to_unicode(qpair[0])\n",
        "      text_b = tokenization.convert_to_unicode(qpair[1])\n",
        "      label = int(qpair[2])\n",
        "      # We will add label  as 0, because None is not supported in converting to features\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "  \n",
        "  def _create_examples(self, lines, set_type):\n",
        "    \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "      guid = \"%s-%d\" % (set_type, i)\n",
        "      if set_type=='test':\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=3:\n",
        "          print(guid, line)\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[1])\n",
        "        text_b = tokenization.convert_to_unicode(line[2])\n",
        "        label = 0 # We will use zero for test as convert_example_to_features doesn't support None\n",
        "      else:\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=6:\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[3])\n",
        "        text_b = tokenization.convert_to_unicode(line[4])\n",
        "        label = int(line[5])\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"return class labels\"\n",
        "    return [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqQ_LHyzcoYW",
        "colab_type": "text"
      },
      "source": [
        "Also we initilize our hyperprams, prepare the training data and initialize TPU config."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7paTY6stK-jU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PAWSProcessor(run_classifier.DataProcessor):\n",
        "  \"\"\"Processor for the Quora Question pair data set.\"\"\"\n",
        "\n",
        "  def get_train_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(self._read_tsv(data_dir+'train.tsv'), 'train')\n",
        "\n",
        "  def get_dev_examples(self, data_dir):\n",
        "    \"\"\"Reading dev.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(data_dir+'dev.tsv'), 'dev')\n",
        "  \n",
        "  def get_test_examples(self, data_dir):\n",
        "    \"\"\"Reading train.tsv and converting to list of InputExample\"\"\"\n",
        "    return self._create_examples(\n",
        "        self._read_tsv(data_dir+'test.tsv'), 'test')\n",
        "  \n",
        "  def convert_examples(self, sentence_pairs):\n",
        "    \"\"\"Given question pairs, conevrting to list of InputExample\"\"\"\n",
        "    examples = []\n",
        "    for (i, qpair) in enumerate(sentence_pairs):\n",
        "      guid = \"predict-%d\" % (i)\n",
        "      # converting questions to utf-8 and creating InputExamples\n",
        "      text_a = tokenization.convert_to_unicode(qpair[0])\n",
        "      text_b = tokenization.convert_to_unicode(qpair[1])\n",
        "      label = int(qpair[2])\n",
        "      # We will add label  as 0, because None is not supported in converting to features\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "\n",
        "  def get_predict_examples(self, sentence_pairs):\n",
        "    \"\"\"Given question pairs, conevrting to list of InputExample\"\"\"\n",
        "    examples = []\n",
        "    for (i, qpair) in enumerate(sentence_pairs):\n",
        "      guid = \"predict-%d\" % (i)\n",
        "      # converting questions to utf-8 and creating InputExamples\n",
        "      text_a = tokenization.convert_to_unicode(qpair[0])\n",
        "      text_b = tokenization.convert_to_unicode(qpair[1])\n",
        "      # We will add label  as 0, because None is not supported in converting to features\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=0))\n",
        "    return examples\n",
        "  \n",
        "  def _create_examples(self, lines, set_type):\n",
        "    \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, line) in enumerate(lines):\n",
        "      guid = \"%s-%d\" % (set_type, i)\n",
        "      if set_type=='test':\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=4:\n",
        "          print(guid, line)\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[1])\n",
        "        text_b = tokenization.convert_to_unicode(line[2])\n",
        "        label = int(line[3]) # We will use zero for test as convert_example_to_features doesn't support None\n",
        "      else:\n",
        "        # removing header and invalid data\n",
        "        if i == 0 or len(line)!=4:\n",
        "          continue\n",
        "        text_a = tokenization.convert_to_unicode(line[1])\n",
        "        text_b = tokenization.convert_to_unicode(line[2])\n",
        "        label = int(line[3])\n",
        "      examples.append(\n",
        "          run_classifier.InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "    return examples\n",
        "\n",
        "  def get_labels(self):\n",
        "    \"return class labels\"\n",
        "    return [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BrXZU_m3Xrf",
        "colab_type": "text"
      },
      "source": [
        "## Model Specifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYVYULZiKvUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 8.0\n",
        "MAX_SEQ_LENGTH = 256\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 500\n",
        "\n",
        "processors = {\n",
        "  \"cola\": run_classifier.ColaProcessor,\n",
        "  \"mnli\": run_classifier.MnliProcessor,\n",
        "  \"mrpc\": run_classifier.MrpcProcessor,\n",
        "  \"qqp\" : QQPProcessor,\n",
        "  \"paws\": PAWSProcessor\n",
        "}\n",
        "processor = processors[TASK.lower()]()\n",
        "label_list = processor.get_labels()\n",
        "\n",
        "# Compute number of train and warmup steps from batch size\n",
        "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "print(len(train_examples))\n",
        "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3iFMeqLaSll",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tune and Run Predictions on a pretrained BERT Model from TF Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXyJRc0OIHEU",
        "colab_type": "text"
      },
      "source": [
        "This section demonstrates fine-tuning from a pre-trained BERT TF Hub module and running predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwcsdbLuIX2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Force TF Hub writes to the GS bucket we provide.\n",
        "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "\n",
        "model_fn = run_classifier_with_tfhub.model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGVYj_rlcDhc",
        "colab_type": "text"
      },
      "source": [
        "At this point, you can now fine-tune the model, evaluate it, and run predictions on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_c8s2AvhgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "def model_train(estimator):\n",
        "  print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
        "  # We'll set sequences to be at most 128 tokens long.\n",
        "  train_features = run_classifier.convert_examples_to_features(\n",
        "      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(train_examples)))\n",
        "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
        "\n",
        "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(estimator):\n",
        "  # Eval the model.\n",
        "  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(eval_examples)))\n",
        "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JkdT9SO3pCM",
        "colab_type": "text"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRhzyk4_WD2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_train(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLQehBr4WHjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_eval(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvsJQK-Y_KTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if STACK:\n",
        "  def model_eval_stack(estimator):\n",
        "  # Eval the model.\n",
        "  processor = processors['paws']()\n",
        "  label_list = processor.get_labels()\n",
        "\n",
        "  eval_examples = processor.get_dev_examples(STACK_DATA_DIR)\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(eval_examples)))\n",
        "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAoH80mL2p8L",
        "colab_type": "text"
      },
      "source": [
        "## Prediction and Analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynDmeatCWLJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_predict_from(estimator,examples):\n",
        "  # Make predictions on a subset of eval examples\n",
        "  prediction_examples = processor.convert_examples(examples)\n",
        "  input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "\n",
        "  for example, prediction in zip(prediction_examples, predictions):\n",
        "    row={'q1': str(example.text_a),'q2': str(example.text_b),'lbl': str(example.label),'pred': str(prediction['probabilities'])}\n",
        "    rows.append(row)\n",
        "  return rows \n",
        "def model_predict(estimator):\n",
        "  # Make predictions on a subset of eval examples\n",
        "  prediction_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "  input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  rows=[]\n",
        "  for example, prediction in zip(prediction_examples, predictions):\n",
        "    row={'q1': str(example.text_a),'q2': str(example.text_b),'lbl': str(example.label),'pred': str(prediction['probabilities'])}\n",
        "    rows.append(row)\n",
        "  return rows \n",
        "data = model_predict(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enTIzFoyulAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_tasks=[\"QQP\"]\n",
        "current_tasks=[\"StackExchange\",'StackCola']\n",
        "predict_results=[]\n",
        "predict_setups=[]\n",
        "for SUB_TASK in current_tasks:\n",
        "  !gsutil -m cp gs://{BUCKET}/Final_Data/{SUB_TASK}/dev.tsv /content/Final_Data/{SUB_TASK}/dev.tsv\n",
        "  \n",
        "  TASK_PREDICT=\"QQP\" if SUB_TASK in [\"QQP\",'StackExchange','StackCola'] else \"PAWS\"\n",
        "  TASK_PREDICT_DIR = 'Final_Data/'+SUB_TASK+'/'\n",
        "  #TASK_PREDICT_DIR='/content'\n",
        "  processor = processors[TASK_PREDICT.lower()]()\n",
        "  label_list = processor.get_labels()\n",
        "  predict_result =model_predict(estimator_from_tfhub,TASK_PREDICT_DIR,processor)\n",
        "  predict_setup={'TASK_PREDICT':TASK_PREDICT+\"_\"+SUB_TASK}\n",
        "  predict_results.append(predict_result)\n",
        "  predict_setups.append(predict_setup)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPBs9mXrugT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def postprocessing(data,predict_set_up):\n",
        "  df = pd.DataFrame(data)\n",
        "  df['pred_lbl']=0\n",
        "  df['type_error']=\"None\"\n",
        "\n",
        "  df['lbl']=df['lbl'].astype(int)\n",
        "  preds=[]\n",
        "  for table in df.pred.values:\n",
        "\n",
        "    pred_row=json.loads(table.replace(\" \",',',1))\n",
        "    preds.append(pred_row)\n",
        "  preds=np.array(preds)\n",
        "  print(preds.shape)\n",
        "  df['first']=preds[:,0].astype(float)\n",
        "  df['second']=preds[:,1].astype(float)\n",
        "  df.loc[ ((df['first'])< (df['second'])),['pred_lbl']]= 1\n",
        "  df.loc[((df['lbl']==1) & (df['pred_lbl']==1)),['type_error']]=\"TP\" \n",
        "  df.loc[((df['lbl']==0) & (df['pred_lbl']==0)),['type_error']]=\"TN\" \n",
        "  df.loc[((df['lbl']==0) & (df['pred_lbl']==1)),['type_error']]=\"FP\" \n",
        "  df.loc[((df['lbl']==1) & (df['pred_lbl']==0)),['type_error']]=\"FN\" \n",
        "  filename=\"prediction_\"+BERT_MODEL+TASK+\"_\"+SUB_TASK+\".csv\"\n",
        "  df.to_csv(filename)\n",
        "  !gsutil  -m cp /content/{filename} gs://{BUCKET}/prediction_results/{filename}\n",
        "  error_acronyms=['TN','TP','FN','FP']\n",
        "  met_dict={error_type:df[df['type_error']==error_type] for error_type in error_acronyms}\n",
        "  met={error_type:met_dict[error_type].shape[0] for error_type in error_acronyms}\n",
        "\n",
        "  #Precision = TP/TP+FP\n",
        "  precision=met['TP']/(met['TP']+met['FP'])\n",
        "  #Recall = TP/TP+FN\n",
        "  recall=met['TP']/(met['TP']+met['FN'])\n",
        "  #F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
        "  f1_score=2*(recall * precision) / (recall + precision)\n",
        "\n",
        "\n",
        "  accuracy=(met['TP']+met['TN'])/sum([met[m] for m in error_acronyms])\n",
        "  score_names=('accuracy','precision','recall', 'f1_score')\n",
        "  sc=(accuracy,precision,recall, f1_score)\n",
        "  scores={}\n",
        "  for name,score in zip(score_names,sc):\n",
        "    print(name, score)\n",
        "    scores={name:score}\n",
        "  out={**predict_set_up,**scores,**met}\n",
        "\n",
        "  e_a=['TN','TP','FN','FP']\n",
        "  errors=['True Negatives','True positives','False Negatives','False positives']\n",
        "  for i, error_type in zip(e_a,errors):\n",
        "    print('The number of '+error_type+' is: ',met_dict[i].shape[0])\n",
        "  print('using ',TASK, SUB_TASK)\n",
        "  print('Analysis of ',TASK, SUB_TASK)\n",
        "  print('Examples of False positives:')\n",
        "  FP=met_dict['FP'][['q1','q2']].head(15).to_numpy()\n",
        "  FN=met_dict['FN'][['q1','q2']].head(15).to_numpy()\n",
        "  for q in range(1,10):\n",
        "    if q<=FP.shape[0]:\n",
        "      print('Example: ',q)\n",
        "      print('Statement 1:',FP[q,0])\n",
        "      print('Statement 2:',FP[q,1])\n",
        "\n",
        "  print()  \n",
        "  print('Examples of False Negatives:')\n",
        "  for q in range(1,10):\n",
        "    if q<=FN.shape[0]:\n",
        "      print('Example: ',q)\n",
        "      print('Statement 1:',FN[q,0])\n",
        "      print('Statement 2:',FN[q,1])\n",
        "      print()\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoRXybzBuUw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "postprocessing(predict_results[0],predict_setups[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7qfWYac2vds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df['pred_lbl']=0\n",
        "df['type_error']=\"None\"\n",
        "\n",
        "df['lbl']=df['lbl'].astype(int)\n",
        "preds=[]\n",
        "for table in df.pred.values:\n",
        "\n",
        "  pred_row=json.loads(table.replace(\" \",',',1))\n",
        "  preds.append(pred_row)\n",
        "preds=np.array(preds)\n",
        "print(preds.shape)\n",
        "df['first']=preds[:,0].astype(float)\n",
        "df['second']=preds[:,1].astype(float)\n",
        "df.loc[ ((df['first'])< (df['second'])),['pred_lbl']]= 1\n",
        "df.loc[((df['lbl']==1) & (df['pred_lbl']==1)),['type_error']]=\"TP\" \n",
        "df.loc[((df['lbl']==0) & (df['pred_lbl']==0)),['type_error']]=\"TN\" \n",
        "df.loc[((df['lbl']==0) & (df['pred_lbl']==1)),['type_error']]=\"FP\" \n",
        "df.loc[((df['lbl']==1) & (df['pred_lbl']==0)),['type_error']]=\"FN\" \n",
        "filename=\"prediction_\"+BERT_MODEL+\"_label_wiki.csv\"\n",
        "df.to_csv(filename)\n",
        "!gsutil  -m cp /content/{filename} gs://{BUCKET}/prediction_results/{filename}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl2tZHCV2w5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FN=df[df['type_error']==\"FN\"]\n",
        "FP=df[df['type_error']==\"FP\"]\n",
        "print('The number of False positives is: ',FP[['q1','q2']].shape[0])\n",
        "print('The number of False Negatives is: ',FN[['q1','q2']].shape[0])\n",
        "\n",
        "print('Analysis of PAWS WIKI')\n",
        "print('Examples of False positives:')\n",
        "FP=FP[['q1','q2']].head(15).to_numpy()\n",
        "FN=FN[['q1','q2']].head(15).to_numpy()\n",
        "for q in range(1,10):\n",
        "  print('Example: ',q)\n",
        "  print('Statement 1:',FP[q,0])\n",
        "  print('Statement 2:',FP[q,1])\n",
        "\n",
        "print()  \n",
        "print('Examples of False Negatives:')\n",
        "for q in range(1,10):\n",
        "  print('Example: ',q)\n",
        "  print('Statement 1:',FN[q,0])\n",
        "  print('Statement 2:',FN[q,1])\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtgLSuh8IdGP",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, you can also load pre-trained BERT models from saved checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu2dQ_TId-uH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if RUN_FROM_CHECKPOINT:\n",
        "  # Setup task specific model and TPU running config.\n",
        "  BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL \n",
        "  print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "  !gsutil ls $BERT_PRETRAINED_DIR\n",
        "\n",
        "  CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "  INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "\n",
        "  model_fn = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True\n",
        "  )\n",
        "\n",
        "  OUTPUT_DIR = OUTPUT_DIR.replace('bert-tfhub', 'bert-checkpoints')\n",
        "  tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "\n",
        "  estimator_from_checkpoints = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=get_run_config(OUTPUT_DIR),\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size=PREDICT_BATCH_SIZE,\n",
        "  )\n",
        "  model_train(estimator_from_checkpoints)\n",
        "  model_eval(estimator_from_checkpoints)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd61zFHgW2aN",
        "colab_type": "text"
      },
      "source": [
        "Now, you can repeat the training, evaluation, and prediction steps."
      ]
    }
  ]
}